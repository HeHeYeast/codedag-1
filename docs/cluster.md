阶段一：锚点识别
目标：找到所有可能作为聚类起点的节点
识别特征（不强制要求，灵活匹配）：

同名同模块的函数被调用多次（如 __getitem__ 在不同context下出现多次）
context字段中包含实例编号（如 #1, #2, #3）
节点的调用模式显示重复性（如从同一个父节点发出多条相同类型的边）
用户可以通过配置文件显式指定某些节点名称/模块作为锚点pattern

识别策略：

遍历所有函数类型的节点
按照 (name, module) 进行分组
如果某个分组包含2个或以上的节点实例，这些节点都是潜在锚点
对于有明确实例编号的节点（从context或name中提取），直接标记为锚点候选

输出：锚点候选列表，按 (name, module) 分组

阶段二：子图提取
目标：从每个锚点出发，提取它控制的完整子图
提取方法：
从锚点节点开始，使用BFS或DFS向下遍历，收集所有可达节点
边界条件（满足其一即停止扩展）：

遇到另一个锚点节点（可能是嵌套的子结构）
遇到叶子节点（没有出边）
遇到返回边或跳出边（目标节点在锚点的祖先路径上，或明显跳出当前子图）
达到预设的最大深度限制（避免过大的子图）

节点收集：

既收集函数节点，也收集变量节点
记录每个节点在子图中的角色（是否是边界节点等）

边收集：

内部边：起点和终点都在子图内的边
输入边：起点在子图外，终点在子图内的边
输出边：起点在子图内，终点在子图外的边

输出：

子图节点集合
子图内部边集合
输入边集合（连接到外部）
输出边集合（连接到外部）


阶段三：结构Hash计算
目标：为每个子图计算唯一的结构签名，用于识别同构的子图
Hash计算方法（基于BFS遍历）：
步骤1：标准化遍历

从锚点开始BFS遍历子图
维护一个visited集合避免重复访问
为每个首次访问的节点分配一个遍历序号

步骤2：生成签名元素
对于每个访问的节点：

提取节点类型（function/variable）
提取规范化的名称（去掉实例编号，如 __getitem__#1 → __getitem__）
提取模块信息
记录当前深度
格式：depth:type:normalized_name:module

对于每条边：

记录边的类型（calls, creates, parameter等）
如果目标节点已访问过（回边/环），记录为：depth:BACK_EDGE:edge_type:target_order
如果目标节点未访问，记录为：depth:EDGE:edge_type

步骤3：排序保证确定性

对于同一个节点的所有出边，按照 (edge_type, target_node_name) 排序后再遍历
这样保证即使边的存储顺序不同，生成的hash也相同

步骤4：计算最终hash

将所有签名元素用分隔符连接成字符串
使用SHA256计算hash值

关键点：

只考虑结构，忽略具体的节点ID和实例编号
处理有向有环图：用visited集合和back-edge标记防止无限循环
变量节点也参与hash，因为它们是结构的一部分

输出：每个子图的64位hash值

阶段四：同构子图分组
目标：将结构相同（hash相同）的子图实例分组
分组方法：

使用hash值作为key
将所有子图按hash分组：{hash: [subgraph1, subgraph2, ...]}
过滤掉只有1个实例的hash组（不需要聚类）

验证步骤：
对于同一个hash组的子图实例，进行二次验证：

检查节点数量是否相同
检查边的数量是否相同
检查输入/输出接口是否一致

输出：待聚类的子图组列表，每组包含2个或以上的同构子图实例

阶段五：节点对应关系建立
目标：对于同一组的多个子图实例，建立节点之间的一一对应关系
匹配方法（基于结构位置）：
选择第一个实例作为"代表实例"，其他实例与它建立映射
匹配算法：

从锚点开始，两个子图同步BFS遍历
在相同的遍历步骤中访问到的节点建立对应关系
使用相同的边排序规则确保遍历顺序一致

处理细节：

函数节点：通过规范化名称和模块匹配
变量节点：通过在调用链中的位置匹配（如"第3个函数的第1个输出变量"）
如果发现不能匹配（节点数不同或位置不对应），说明hash冲突，不应该聚类

输出：
对于每个非代表实例，生成一个映射表：
{instance_node_id → representative_node_id}

阶段六：节点融合与元数据记录
目标：将多个实例的节点融合成一个节点，并记录实例数量
融合策略：
基于代表实例创建融合后的节点，其他实例的节点都映射到代表实例
节点属性处理：

基本属性（保留代表实例的）：

id：使用代表实例的节点ID
name：去掉实例编号（如 __getitem__#1 → __getitem__）
type：保持不变
module：保持不变
context：去掉实例编号，或标记为聚类节点


新增聚类元数据：

   cluster_info: {
     is_clustered: true,
     instance_count: N,  // 这个节点代表N个原始节点
     original_ids: [id1, id2, id3, ...],  // 所有原始实例的ID
     representative_id: id1  // 代表实例的ID
   }

性能数据聚合：

execution_time_ms：求和（总时间）
memory相关：

max值：取所有实例的最大值
total：求和


新增统计字段：



     performance_stats: {
       execution_time: {
         total: sum,
         mean: avg,
         std: standard_deviation,
         min: min,
         max: max,
         instances: [t1, t2, t3, ...]  // 每个实例的值
       },
       memory_allocated_mb: { ... },
       ...
     }
关键规则：

同一个聚类子图内的所有节点的 instance_count 必须相同
这是因为它们是作为一个整体被重复执行的
如果发现instance_count不一致，说明子图边界划分有问题

输出：融合后的节点列表，每个节点都包含完整的聚类元数据

阶段七：内部边处理
目标：处理子图内部的边连接
处理方法：
直接使用代表实例的内部边结构，但更新边的端点ID为融合后的节点ID
边属性更新：

from_id, to_id：更新为融合后的节点ID（实际就是代表实例的ID）
edge_type：保持不变
新增元数据：

  cluster_info: {
    is_clustered: true,
    instance_count: N,  // 这条边代表N条原始边
    original_edge_ids: [...]  // 如果边有ID的话
  }
验证：

确保内部边的两个端点都在融合后的子图内
检查边的数量是否与代表实例一致

输出：融合后的内部边列表

阶段八：外部边处理
目标：处理外部节点与聚类子图之间的连接
边的分类：

输入边：外部节点 → 子图内节点
输出边：子图内节点 → 外部节点

处理流程：
步骤1：收集所有外部边
遍历每个子图实例，收集所有跨越子图边界的边
步骤2：映射端点

对于输入边：目标节点从原始实例ID映射到融合节点ID
对于输出边：源节点从原始实例ID映射到融合节点ID

步骤3：边的去重与合并
多个实例可能有完全相同的外部连接，需要识别：

按照 (from_id, to_id, edge_type) 分组
如果多个实例有相同的边，可以选择：

选项A：保留多条边，但标记它们来自聚类
选项B：合并成一条边，记录重复次数



边元数据（选项B）：
{
  from_id: xxx,
  to_id: xxx,
  type: "calls",
  cluster_info: {
    is_from_cluster: true,
    multiplicity: N,  // 表示N个实例都有这条边
    instance_indices: [0, 1, 2, ...]  // 哪些实例有这条边
  }
}
特殊情况处理：

如果不同实例连接到不同的外部节点，则保留所有边，不合并
例如：external_node_1 → __getitem__#1 和 external_node_2 → __getitem__#2 应该保留为两条边

输出：处理后的外部边列表

阶段九：图重建
目标：用融合后的节点和边构建新的图结构
重建步骤：

创建新图：

复制所有未被聚类的原始节点
添加所有融合后的节点（替换原始的多个实例）


更新边连接：

保留未涉及聚类节点的原始边
添加聚类子图的内部边
添加处理后的外部边
删除已被融合的实例节点相关的边


更新节点引用：

确保所有边的from_id和to_id都指向新图中存在的节点
更新父子关系、调用链等引用


验证图的完整性：

检查是否有悬空边（指向不存在的节点）
检查是否有孤立节点（没有任何边连接）
验证聚类节点的instance_count一致性



输出：重建后的完整图结构

阶段十：元数据总结
目标：生成聚类统计信息
生成内容：

全局统计：

原始节点数 vs 聚类后节点数
原始边数 vs 聚类后边数
压缩比例：(原始节点数 - 新节点数) / 原始节点数
聚类组数量
平均每组实例数


每个聚类组的信息：

   cluster_groups: [
     {
       cluster_id: "cluster_001",
       pattern_hash: "abc123...",
       anchor_name: "__getitem__",
       instance_count: 4,
       node_count_per_instance: 15,  // 每个实例有15个节点
       total_nodes_saved: 45,  // 节省了45个节点（4-1）×15
       representative_id: 123,
       pattern_description: "数据预处理管道：getitem->preprocess->transform"
     },
     ...
   ]

性能影响分析：

聚类前后的总执行时间（应该不变，只是结构简化）
聚类前后的峰值内存（可能略有变化）
最大的聚类组（节省最多节点的）



输出：完整的聚类报告

关键约束与验证
约束1：同一子图内节点的instance_count必须相同

在阶段六完成后验证
如果发现不一致，说明子图边界划分错误，需要调整

约束2：融合前后图的语义等价

调用关系保持不变
数据流保持不变
只是去除了重复的结构

约束3：可逆性

保留足够的元数据，使得可以"展开"聚类节点
用户可以查看任意聚类节点的具体实例

约束4：处理嵌套聚类

一个子图内部可能包含另一个聚类
按照从内到外的顺序处理
或者只聚类最外层，内层保持原样


输出格式
聚类后的图结构保持原有的JSON格式，但节点增加聚类元数据：
节点字段：
- 原有字段：id, name, type, module, context, performance, input_edges, output_edges
- 新增字段：cluster_info
  - is_clustered: bool
  - instance_count: int (关键！表示这个节点代表几个原始节点)
  - original_ids: [id1, id2, ...]
  - representative_id: id
  - pattern_hash: string

边字段：
- 原有字段：type, from_id, to_id
- 新增字段：cluster_info
  - is_from_cluster: bool
  - multiplicity: int (如果合并了多条边)
  - instance_indices: [0, 1, 2, ...]
这样设计的话，同一个白盒子图内的所有节点都会有相同的 instance_count 值，清晰地表明它们是作为一个整体被重复执行了N次。